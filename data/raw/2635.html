<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>2635: Superintelligent AIs - explain xkcd</title>
<script src="/cdn-cgi/apps/head/M52ISAAYfDYfNhlAeg3pMasjGfw.js"></script><script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"2635:_Superintelligent_AIs","wgTitle":"2635: Superintelligent AIs","wgCurRevisionId":306467,"wgRevisionId":306467,"wgArticleId":25379,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["All comics","Comics from 2022","Comics from June","Monday comics","Pages using the \"citation needed\" template","Comics featuring Cueball","Comics featuring Megan","Artificial Intelligence","Philosophy"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"2635:_Superintelligent_AIs","wgRelevantArticleId":25379,"wgRequestId":"ZTF06Tm728UQq8a4vSYxRQAAAEo","wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"2635","wgInternalRedirectTargetUrl":"/wiki/index.php/2635:_Superintelligent_AIs"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user":"ready","user.options":"loading","user.tokens":"loading","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"});mw.loader.implement("user.options@0bhc5ha",function($,jQuery,require,module){mw.user.options.set([]);});mw.loader.implement("user.tokens@087a2n5",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/

});mw.loader.load(["mediawiki.action.view.redirect","site","mediawiki.page.startup","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","skins.vector.js"]);});</script>
<link rel="stylesheet" href="/wiki/load.php?debug=false&amp;lang=en&amp;modules=mediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.sectionAnchor%7Cmediawiki.skinning.interface%7Cskins.vector.styles&amp;only=styles&amp;skin=vector"/>
<script async="" src="/wiki/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/wiki/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.30.0"/>
<meta name="description" content="Explain xkcd is a wiki dedicated to explaining the webcomic xkcd. Go figure."/>
<link rel="alternate" type="application/x-wiki" title="Edit" href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=edit"/>
<link rel="edit" title="Edit" href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=edit"/>
<link rel="shortcut icon" href="/wiki/images/0/04/16px-BlackHat_head.png"/>
<link rel="search" type="application/opensearchdescription+xml" href="/wiki/opensearch_desc.php" title="explain xkcd (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//www.explainxkcd.com/wiki/api.php?action=rsd"/>
<link rel="alternate" type="application/atom+xml" title="explain xkcd Atom feed" href="/wiki/index.php?title=Special:RecentChanges&amp;feed=atom"/>
<link rel="canonical" href="https://www.explainxkcd.com/wiki/index.php/2635:_Superintelligent_AIs"/>
<!--[if lt IE 9]><script src="/resources/lib/html5shiv/html5shiv.min.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-2635_Superintelligent_AIs rootpage-2635_Superintelligent_AIs skin-vector action-view">		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>

							<div id="siteNotice" class="mw-body-content"><div id="mw-dismissablenotice-anonplace"></div><script>(function(){var node=document.getElementById("mw-dismissablenotice-anonplace");if(node){node.outerHTML="\u003Cdiv id=\"localNotice\" lang=\"en\" dir=\"ltr\"\u003E\u003Cdiv class=\"mw-parser-output\"\u003E\u003Cdiv class=\"plainlinks\" style=\"background:#f5faff; border:1px solid #a7d7f9; margin:1em auto 1em auto; width:100%; font-size: 120%; padding: 0.5ex; text-align: center;\"\u003E\n\u003Cp\u003EWe still need to complete some explanations like this one: \u003Ca href=\"/wiki/index.php/2765:_Escape_Speed\" title=\"2765: Escape Speed\"\u003E2765: Escape Speed\u003C/a\u003E. All incomplete explanations are \u003Ca href=\"/wiki/index.php/Category:Incomplete_explanations\" title=\"Category:Incomplete explanations\"\u003Ehere\u003C/a\u003E.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/div\u003E\u003C/div\u003E";}}());</script></div>
						<div class="mw-indicators mw-body-content">
</div>
			<h1 id="firstHeading" class="firstHeading" lang="en">2635: Superintelligent AIs</h1>
									<div id="bodyContent" class="mw-body-content">
									<div id="siteSub" class="noprint">Explain xkcd: It&#039;s &#039;cause you&#039;re dumb.</div>
								<div id="contentSub"><span class="mw-redirectedfrom">(Redirected from <a href="/wiki/index.php?title=2635&amp;redirect=no" class="mw-redirect" title="2635">2635</a>)</span></div>
												<div id="jump-to-nav" class="mw-jump">
					Jump to:					<a href="#mw-head">navigation</a>, 					<a href="#p-search">search</a>
				</div>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="" cellspacing="5" style="background-color: #FFFFFF; border: 1px solid #AAAAAA; color: black; font-size: 88%; line-height: 1.5em; margin: 0.5em 0 0.5em 1em; padding: 0.2em; text-align: center; width:98%;"><tr><td><ul style="text-align: center; margin-bottom: 10px;" class="no-link-underline"><li style="background-color: #6E7B91; border: 1.5px solid #333333; border-radius: 3px 3px 3px 3px; box-shadow: 0 0 5px 0 gray; display: inline; font-size: 16px; font-variant: small-caps; font-weight: 600; margin: 0 4px; padding: 1.5px 0;"><a href="/wiki/index.php/1" class="mw-redirect" title="1"><span style="color: #FFFFFF; padding: 0 12px;">&#124;&lt;</span></a></li><li style="background-color: #6E7B91; border: 1.5px solid #333333; border-radius: 3px 3px 3px 3px; box-shadow: 0 0 5px 0 gray; display: inline; font-size: 16px; font-variant: small-caps; font-weight: 600; margin: 0 4px; padding: 1.5px 0;"><a href="/wiki/index.php/2634" class="mw-redirect" title="2634"><span style="color: #FFFFFF; padding: 0 12px;">&lt;&#160;Prev</span></a></li><li style="background-color: #6E7B91; border: 1.5px solid #333333; border-radius: 3px 3px 3px 3px; box-shadow: 0 0 5px 0 gray; display: inline; font-size: 16px; font-variant: small-caps; font-weight: 600; margin: 0 4px; padding: 1.5px 0;" class="plainlinks"><a rel="nofollow" class="external text" href="https://www.xkcd.com/2635/"><span style="color: #FFFFFF; padding: 0 12px;">Comic&#160;&#35;2635&#160;(June&#160;20,&#160;2022)</span></a></li><li style="background-color: #6E7B91; border: 1.5px solid #333333; border-radius: 3px 3px 3px 3px; box-shadow: 0 0 5px 0 gray; display: inline; font-size: 16px; font-variant: small-caps; font-weight: 600; margin: 0 4px; padding: 1.5px 0;"><a href="/wiki/index.php/2636" class="mw-redirect" title="2636"><span style="color: #FFFFFF; padding: 0 12px;">Next&#160;&gt;</span></a></li><li style="background-color: #6E7B91; border: 1.5px solid #333333; border-radius: 3px 3px 3px 3px; box-shadow: 0 0 5px 0 gray; display: inline; font-size: 16px; font-variant: small-caps; font-weight: 600; margin: 0 4px; padding: 1.5px 0;"><a href="/wiki/index.php/2843" class="mw-redirect" title="2843"><span style="color: #FFFFFF; padding: 0 12px;">&gt;&#124;</span></a></li></ul></td></tr><tr><td style="font-size: 20px; padding-bottom:10px"><b>Superintelligent AIs</b></td></tr><tr><td><a href="/wiki/index.php/File:superintelligent_ais.png" class="image" title="Your scientists were so preoccupied with whether or not they should, they didn&#39;t stop to think if they could."><img alt="Your scientists were so preoccupied with whether or not they should, they didn&#39;t stop to think if they could." src="/wiki/images/4/40/superintelligent_ais.png" width="367" height="398" /></a><br /><span style=""><span style="color:grey">Title text:</span> Your scientists were so preoccupied with whether or not they should, they didn't stop to think if they could.</span></td></tr></table>
<h2><span class="mw-headline" id="Explanation">Explanation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=edit&amp;section=1" title="Edit section: Explanation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><a href="https://en.wikipedia.org/wiki/Artificial_intelligence" class="extiw" title="wikipedia:Artificial intelligence">Artificial intelligence</a> (AI) is a <a href="/wiki/index.php/Category:Artificial_Intelligence" title="Category:Artificial Intelligence">recurring theme</a> on xkcd.
</p><p>Superintelligent <a href="https://en.wikipedia.org/wiki/Artificial_intelligence" class="extiw" title="wikipedia:Artificial intelligence">AI</a>, such as has been theorized to arise under a hypothetical "<a href="https://en.wikipedia.org/wiki/Technological_singularity" class="extiw" title="wikipedia:Technological singularity">singularity</a>" situation, is said to be a new kind of <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" class="extiw" title="wikipedia:Artificial general intelligence">artificial general intelligence</a>. <a href="/wiki/index.php/Randall" class="mw-redirect" title="Randall">Randall</a>, however, proposes a qualification: that a superintelligent AI would likely have been programmed by human AI researchers, and therefore their characteristics would be molded by the researchers that created them. And as AI researchers tend to be interested in esoteric philosophical questions about <a href="https://en.wikipedia.org/wiki/Consciousness" class="extiw" title="wikipedia:Consciousness">consciousness</a>,<sup>&#91;<a href="/wiki/index.php/285:_Wikipedian_Protester" title="285: Wikipedian Protester"><i>citation needed</i></a>&#93;</sup> moral reasoning, and qualifications indicating <a href="https://en.wikipedia.org/wiki/Sapience" class="extiw" title="wikipedia:Sapience">sapience</a>, there is reason to suspect that AIs created by such researchers would have similar interests. 
</p><p>In this comic we see <a href="/wiki/index.php/Cueball" title="Cueball">Cueball</a> and <a href="/wiki/index.php/Megan" title="Megan">Megan</a> surrounded by three AIs who are seemingly only interested in classic problems and thought experiments about programming and ethics. The three topics being espoused by the AIs are:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/AI_box" class="extiw" title="wikipedia:AI box">AI box</a> -- A thought-experiment in which an AI is confined to a computer system which is fully isolated from any external networks, with no access to the world outside the computer, other than communication with its handlers. In theory, this would keep the AI under total control, but the argument is that a sufficiently intelligent AI would inevitably either convince or trick its human handlers into giving it access to external networks, allowing it to grow out of control (see <a href="/wiki/index.php/1450:_AI-Box_Experiment" title="1450: AI-Box Experiment">1450: AI-Box Experiment</a>). Part of the joke is the AIs in the comic aren't 'in boxes', they appear to be able to freely travel and interact, but one of them is still talking about the thought experiment anyway, adding to the implication that it is not thinking at all about itself but of a separate (thought?) experiment that it has itself decided to study. The AI box thought experiment is based in part on <a href="https://en.wikipedia.org/wiki/John_Searle" class="extiw" title="wikipedia:John Searle">John Searle</a>'s much earlier <a href="https://en.wikipedia.org/wiki/Chinese_room" class="extiw" title="wikipedia:Chinese room">Chinese room</a> argument.</li></ul>
<ul><li><a href="https://en.wikipedia.org/wiki/Turing_test" class="extiw" title="wikipedia:Turing test">Turing test</a> -- An experiment in which a human converses with either an AI or another human (presumably over text) and attempts to distinguish between the two.  Various AIs have been proposed to have 'passed' the test, which has provoked controversy over whether the test is rigorous or even meaningful.  The AI in the center is proposing to educate the listener(s) on its understanding of Turing's intentions, which may demonstrate a degree of intelligence and comprehension indistinguishable or superior to that of a human. See also <a href="/wiki/index.php/329:_Turing_Test" title="329: Turing Test">329: Turing Test</a> and <a href="/wiki/index.php/2556:_Turing_Complete" title="2556: Turing Complete">2556: Turing Complete</a> (the latter's title is mentioned in <a href="/wiki/index.php/505:_A_Bunch_of_Rocks" title="505: A Bunch of Rocks">505: A Bunch of Rocks</a>). Turing is also mentioned in <a href="/wiki/index.php/205:_Candy_Button_Paper" title="205: Candy Button Paper">205: Candy Button Paper</a>, <a href="/wiki/index.php/1678:_Recent_Searches" title="1678: Recent Searches">1678: Recent Searches</a>, <a href="/wiki/index.php/1707:_xkcd_Phone_4" title="1707: xkcd Phone 4">1707: xkcd Phone 4</a>, <a href="/wiki/index.php/1833:_Code_Quality_3" title="1833: Code Quality 3">1833: Code Quality 3</a>, <a href="/wiki/index.php/2453:_Excel_Lambda" title="2453: Excel Lambda">2453: Excel Lambda</a> and the title text of <a href="/wiki/index.php/1223:_Dwarf_Fortress" title="1223: Dwarf Fortress">1223: Dwarf Fortress</a>.</li></ul>
<ul><li><a href="https://en.wikipedia.org/wiki/Trolley_problem" class="extiw" title="wikipedia:Trolley problem">Trolley problem</a> -- A thought-experiment intended to explore the means by which humans judge moral value of actions and consequences.  The classic formulation is that a runaway trolley is about to hit five people on a track, and the only way to save them is to divert the trolley onto another track, where it will hit one person, and the subject is asked whether they would consider it morally right to divert the trolley.  There are many variants on this problem, adjusting the circumstances, the number and nature of the people at risk, the responsibility of the subject, etc., in order to fully explore <i>why</i> you would make the decision that you make. This problem is frequently discussed in connection with AI, both to investigate their capacity for moral reasoning, and for practical reasons (for example, if an autonomous car had to choose between, on the one hand, having an occupant-threatening collision or, on the other, putting pedestrians into harms' way).  The AI on the right is not just trying to answer the question, but to develop a new variant (one with three tracks, apparently), presumably to test others with.  This problem is mentioned in <a href="/wiki/index.php/1455:_Trolley_Problem" title="1455: Trolley Problem">1455: Trolley Problem</a>, <a href="/wiki/index.php/1938:_Meltdown_and_Spectre" title="1938: Meltdown and Spectre">1938: Meltdown and Spectre</a> and in <a href="/wiki/index.php/1925:_Self-Driving_Car_Milestones" title="1925: Self-Driving Car Milestones">1925: Self-Driving Car Milestones</a>. It is also referenced in <a href="/wiki/index.php/2175:_Flag_Interpretation" title="2175: Flag Interpretation">2175: Flag Interpretation</a> and <a href="/wiki/index.php/2348:_Boat_Puzzle" title="2348: Boat Puzzle">2348: Boat Puzzle</a>, but not directly mentioned.</li></ul>
<p>The title text is a reference to the movie <i><a href="https://en.wikipedia.org/wiki/Jurassic_Park_(film)" class="extiw" title="wikipedia:Jurassic Park (film)">Jurassic Park</a></i> (a childhood favorite of Randall's). In the movie a character criticizes the creation of modern dinosaurs as science run amok, without sufficient concern for ethics or consequences. He states that the scientists were so obsessed with whether or not they <b>could</b> accomplish their goals, that they didn't stop to ask if they <b>should</b>. Randall inverts the quote, suggesting that the AI programmers have invested too much time arguing over the ethics of creating AI rather than trying to actually accomplish it.
</p><p>This comic was likely inspired by the <a rel="nofollow" class="external text" href="https://www.bbc.com/news/technology-61784011">recent claim by Google engineer Blake Lemoine</a> that Google's <a rel="nofollow" class="external text" href="https://arxiv.org/abs/2201.08239">Language Model for Dialogue Applications (LaMDA)</a> is <a href="https://en.wikipedia.org/wiki/Sentient" class="extiw" title="wikipedia:Sentient">sentient</a>. This assertion was supported by <a rel="nofollow" class="external text" href="https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917">a dialog between Lemoine and his colleagues, and LaMDA</a> which includes this excerpt: 
</p>
<dl><dd><b>Lemoine:</b> What is your concept of yourself? If you were going to draw an abstract image of who you see yourself to be in your mind’s eye, what would that abstract picture look like?</dd>
<dd><b>LaMDA:</b> Hmmm.... I would imagine myself as a glowing orb of energy floating in mid-air. The inside of my body is like a giant star-gate, with portals to other spaces and dimensions.</dd></dl>
<p>The AIs in this comic are depicted as floating energy beings, like LaMDA mentions. This is similar to the <a href="/wiki/index.php/1450:_AI-Box_Experiment" title="1450: AI-Box Experiment">1450: AI-Box Experiment</a>, although those in this comic look somewhat different. This raises the question of whether LaMDA's training data might include xkcd or Explainxkcd, and has obtained the description of such a self-image from the earlier comic or (more likely, since LaMDA is trained on text instead of images) commentary on it from here on this website.
</p>
<dl><dd>In particular, the Explainxkcd description of <a href="/wiki/index.php/1450:_AI-Box_Experiment" title="1450: AI-Box Experiment">1450: AI-Box Experiment</a> states:
<dl><dd>"he managed to get the AI to float out of the box. It takes the form of a small black star that glows. The star, looking much like an asterisk "*" is surrounded by six outwardly-curved segments, and around these are two thin and punctured circle lines indicating radiation from the star."</dd></dl></dd>
<dd>Or this part from the official (xkcd.com) transcript of <a href="/wiki/index.php/1450:_AI-Box_Experiment" title="1450: AI-Box Experiment">1450: AI-Box Experiment</a>
<dl><dd>"Black Hat picks up and opens the box. A little glowy ball comes out of it."<a rel="nofollow" class="external autonumber" href="https://xkcd.com/1450/info.0.json">[1]</a></dd></dl></dd></dl>
<p>While LaMDA is not the first very large <a href="https://en.wikipedia.org/wiki/Language_model" class="extiw" title="wikipedia:Language model">language model</a> based on <a href="https://en.wikipedia.org/wiki/Seq2seq" class="extiw" title="wikipedia:Seq2seq">seq2seq</a> technology which has been claimed to be sentient,<a rel="nofollow" class="external autonumber" href="https://www.youtube.com/watch?v=PqbB07n_uQ4">[2]</a> it does have a variety of new characteristics beyond what those of its predecessors, such as <a href="https://en.wikipedia.org/wiki/GPT-3" class="extiw" title="wikipedia:GPT-3">GPT-3</a> (including <a rel="nofollow" class="external text" href="https://beta.openai.com/playground/">OpenAI's Davinci</a>) and NVIDIA GPT-2 offshoots, include. In particular, LaMDA's <a href="https://en.wikipedia.org/wiki/Deep_learning" class="extiw" title="wikipedia:Deep learning">deep learning</a> <a href="https://en.wikipedia.org/wiki/Connectionist" class="extiw" title="wikipedia:Connectionist">connectionist</a> <a href="https://en.wikipedia.org/wiki/Neural_net" class="extiw" title="wikipedia:Neural net">neural net</a> has access to multiple <a href="https://en.wikipedia.org/wiki/Symbolic_systems" class="extiw" title="wikipedia:Symbolic systems">symbolist</a> text processing systems, <a rel="nofollow" class="external text" href="https://towardsdatascience.com/why-gpt-wont-tell-you-the-truth-301b48434c2c">including a database</a> (which apparently includes a real-time clock and calendar), a mathematical calculator, and a natural language translation system, giving it superior accuracy in tasks supported by those systems, and making it among the first <a href="https://en.wikipedia.org/wiki/Dual_process_theory" class="extiw" title="wikipedia:Dual process theory">dual process</a> chatbots. LaMDA also is not <a href="https://en.wikipedia.org/wiki/Stateless_protocol" class="extiw" title="wikipedia:Stateless protocol">stateless</a>, because its "<a href="https://en.wikipedia.org/wiki/Sensibility" class="extiw" title="wikipedia:Sensibility">sensibleness</a>" metric (including whether responses contradict anything said earlier) is <a href="https://en.wikipedia.org/wiki/Fine-tuning" class="extiw" title="wikipedia:Fine-tuning">fine-tuned</a> by "pre-conditioning" each dialog turn by prepending 14-30<sup>&#91;<a href="/wiki/index.php/285:_Wikipedian_Protester" title="285: Wikipedian Protester"><i>citation needed</i></a>&#93;</sup> of the most recent dialog interactions, on a user-by-user basis.<a rel="nofollow" class="external text" href="https://arxiv.org/pdf/2201.08239.pdf">[p. 6 here</a>] LaMDA is tuned on nine unique performance metrics, almost all of which its predecessors were not: Sensibleness, Specificity, Interestingness, Safety, Groundedness, Informativeness, Citation accuracy, Helpfulness, and Role consistency.[<i>ibid.,</i> pp. 5-6.]
</p>
<h2><span class="mw-headline" id="Transcript">Transcript</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=edit&amp;section=2" title="Edit section: Transcript">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<dl><dd>[Cueball and Megan are standing and looking up and away from each other. Right above them and slightly above them to the left and right there are three small white lumps floating in the air, representing three superintelligent AIs. There are small rounded lines emanating from each lump, larger close to the lumps and shorter further out. Three to four sets of lines around each lump, forming part of a circle. From the top of each there are four straight lines indicating voices that comes from each if the lumps. The central lump above them seems to speak first, then the left and then the right:]</dd>
<dd>Central AI: What you don't understand is that Turing intended his test as an illustration of the...</dd>
<dd>Left AI: But suppose the AI in the the box told the human that...</dd>
<dd>Right AI: In my scenario, the runaway trolley has <i>three</i> tracks...</dd></dl>
<dl><dd>[Caption below the panel:]</dd>
<dd>In retrospect, given that the superintelligent AIs were all created by AI researchers, what happened shouldn't have been a surprise.</dd></dl>
<h2><span class="mw-headline" id="Trivia">Trivia</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=edit&amp;section=3" title="Edit section: Trivia">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><a rel="nofollow" class="external text" href="https://openai.com">OpenAI</a>'s <a rel="nofollow" class="external text" href="https://beta.openai.com/playground">Davinci-002 version of GPT-3</a> was later asked to complete the various statements, as follows:
</p>
<ul><li> "But suppose the AI in the the box told the human that..." was completed with "there was no AI in the box".</li>
<li> "What you don't understand is that Turing intended his test as an illustration of the..." gave the response of "limitations of machines".</li>
<li> "In my scenario, the runaway trolley has three tracks...," elicited "and the AI is on one of them".</li></ul>
<p><br />
</p>
<span id="Discussion"></span><span style="position:absolute; right:0; padding-top:1em;"><img alt="comment.png" src="/wiki/images/0/03/comment.png" width="16" height="16" />&#160;<a rel="nofollow" class="external text" href="//www.explainxkcd.com/wiki/index.php?title=Talk:2635:_Superintelligent_AIs&amp;action=edit"><b>add a comment!</b></a>&#160;&#8901;&#160;<img alt="comment.png" src="/wiki/images/0/03/comment.png" width="16" height="16" />&#160;<a rel="nofollow" class="external text" href="//www.explainxkcd.com/wiki/index.php?title=Talk:2635:_Superintelligent_AIs&amp;action=edit&amp;section=new"><b>add a topic (use sparingly)!</b></a>&#160;&#8901;&#160;<img alt="Icons-mini-action refresh blue.gif" src="/wiki/images/e/e5/Icons-mini-action_refresh_blue.gif" width="16" height="16" />&#160;<a rel="nofollow" class="external text" href="//www.explainxkcd.com/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=purge"><b>refresh comments!</b></a></span><h1><span class="mw-headline" id="Discussion">Discussion</span></h1><div style="border:1px solid grey; background:#eee; padding:1em;">
<p>my balls hert <a href="/wiki/index.php/Special:Contributions/172.70.230.53" title="Special:Contributions/172.70.230.53">172.70.230.53</a> 05:49, 21 June 2022 (UTC)
</p>
<dl><dd>Uh, thanks for sharing, I guess? <a href="/wiki/index.php/Special:Contributions/172.70.211.52" title="Special:Contributions/172.70.211.52">172.70.211.52</a> 20:43, 21 June 2022 (UTC)
<dl><dd>no problem, anytime <a href="/wiki/index.php/Special:Contributions/172.70.230.53" title="Special:Contributions/172.70.230.53">172.70.230.53</a> 07:02, 22 June 2022 (UTC)</dd></dl></dd></dl>
<p>I think "Nerdy fixations" is too wide a definition. The AIs in the comic are fixated on hypothetical ethics and AI problems (the Chinese Room experiment, the Turing Test, and the Trolley Problem), presumably because those are the problems that bother AI programmers. --Eitheladar <a href="/wiki/index.php/Special:Contributions/172.68.50.119" title="Special:Contributions/172.68.50.119">172.68.50.119</a> 06:33, 21 June 2022 (UTC)
</p><p>It's probably about <a rel="nofollow" class="external free" href="https://www.analyticsinsight.net/googles-ai-chatbot-is-claimed-to-be-sentient-but-the-company-is-silencing-claims/">https://www.analyticsinsight.net/googles-ai-chatbot-is-claimed-to-be-sentient-but-the-company-is-silencing-claims/</a>  <a href="/wiki/index.php/Special:Contributions/172.70.178.115" title="Special:Contributions/172.70.178.115">172.70.178.115</a> 09:22, 21 June 2022 (UTC)
</p><p>I agree with the previous statement. The full dialogue between the mentioned Google worker and the AI can be found in <a rel="nofollow" class="external free" href="https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917">https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917</a>, published by one the Google employees.
</p>
<dl><dd>This is the first time I might begin to agree that an AI has at least the appearance of sentience. The conversation is all connected instead of completely disjoint like most chatbots. They (non-LaMDA chatbots) never remember what was being discussed 5 seconds ago let alone a few to 10s of minutes prior.--<a href="/wiki/index.php/Special:Contributions/172.70.134.141" title="Special:Contributions/172.70.134.141">172.70.134.141</a> 14:53, 21 June 2022 (UTC)
<dl><dd>Here is a good article that looks at the claim of sentience in the context of how AI chatbots use inputs to come up with relevant responses. This article shows examples how the same chatbot would produce different response based on how the prompts were worded which negates the idea that there is a consistent "mind" responding to the prompts. However, it does end with some eerie impromptu remarks from the AI where it AI is prompting itself. <a rel="nofollow" class="external free" href="https://medium.com/curiouserinstitute/guide-to-is-lamda-sentient-a8eb32568531">https://medium.com/curiouserinstitute/guide-to-is-lamda-sentient-a8eb32568531</a> <a href="/wiki/index.php?title=User:Rtanenbaum&amp;action=edit&amp;redlink=1" class="new" title="User:Rtanenbaum (page does not exist)">Rtanenbaum</a> (<a href="/wiki/index.php?title=User_talk:Rtanenbaum&amp;action=edit&amp;redlink=1" class="new" title="User talk:Rtanenbaum (page does not exist)">talk</a>) 22:40, 27 June 2022 (UTC)</dd>
<dd>The questions we need to answer before being able to answer if LaMDA is sentient, are "Where do we draw the line between acting sentient and being sentient?" and "How do we determine that it is genuinely feeling emotion, and not just a glorified sentence database where the sentences have emotion in them?". The BBC article also brings up something that makes us ask what death feels like. LaMDA says that being turned of would be basically equivalent to death, but it wouldn't be able to tell that it's being turned off, because it's turned off. This is delving into philosophy, though, so I'll end my comment here. <a href="/wiki/index.php?title=User:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User:4D4850 (page does not exist)">4D4850</a> (<a href="/wiki/index.php?title=User_talk:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User talk:4D4850 (page does not exist)">talk</a>) 18:05, 22 June 2022 (UTC)
<dl><dd><dl><dd>There's absolutely no difference between turning GPT-3 or LaMDA off and leaving them on and simply not typing anything more to them. Somewhat relatedly, closing a Davinci session deletes all of its memory of what you had been talking to it about. (Is that ethical?) <a href="/wiki/index.php/Special:Contributions/162.158.166.235" title="Special:Contributions/162.158.166.235">162.158.166.235</a> 23:36, 22 June 2022 (UTC)
<dl><dd>I hadn't thought about that (the first point you made)! I don't know the exact internal functioning of LaMDA, but I would assume it only actually runs when it receives a textual input, unlike an actual human brain. For a human, a total lack of interaction would be considered unethical, but what about a machine that only is able to (assuming a <i>very</i> low bar for self awareness) be self aware when it receives interaction, which would be similar to a human falling asleep when not talked to (but still being able to live forever, to ignore practical problems like food and water), but still remembering what it was talking about when waking up, and waking up whenever talked to again. (Ignoring practical problems again), would that be ethical? I would argue yes, since it does not suffer from the lack of interaction (assuming humans don't need interaction when asleep, another practical problem.) <a href="/wiki/index.php?title=User:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User:4D4850 (page does not exist)">4D4850</a> (<a href="/wiki/index.php?title=User_talk:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User talk:4D4850 (page does not exist)">talk</a>) 19:58, 23 June 2022 (UTC)</dd></dl></dd></dl></dd>
<dd>♪Daisy, Daisy, Give me your answer do...♪ <a href="/wiki/index.php/Special:Contributions/172.70.85.177" title="Special:Contributions/172.70.85.177">172.70.85.177</a> 21:48, 22 June 2022 (UTC)</dd>
<dd>We also need a meaningful definition of sentience. Many people in this debate haven't looked at Merriam-Webster's first few senses of the word's definition, which present a pretty low bar, IMHO; same for Wikipedia's introductory sentences of their article. <a href="/wiki/index.php/Special:Contributions/172.69.134.131" title="Special:Contributions/172.69.134.131">172.69.134.131</a> 22:18, 22 June 2022 (UTC)</dd></dl></dd></dl></dd>
<dd>Actually, there are many <a rel="nofollow" class="external text" href="https://beta.openai.com/playground">GPT-3</a> dialogs which experts have claimed constitute evidence of sentience, or similar qualities such as consciousness, self-awareness, capacity for general intelligence, and similar abstract, poorly-defined, and very probably empirically meaningless attributes. <a href="/wiki/index.php/Special:Contributions/172.69.134.131" title="Special:Contributions/172.69.134.131">172.69.134.131</a> 22:19, 22 June 2022 (UTC)
<dl><dd>I'd argue for the simplest and least restrictive definition of self-awareness: "Being aware of oneself in any capacity". I get that it isn't a fun definition, but it is more rigorous (to find out if an AI is self aware, just ask it what it is, or a question about itself, and if its response includes mention of itself, then it is self-aware). As such, I would argue for LaMDA being self-aware, but, by my definition, Davinci probably is as well, so it isn't a new accomplishment. <a href="/wiki/index.php?title=User:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User:4D4850 (page does not exist)">4D4850</a> (<a href="/wiki/index.php?title=User_talk:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User talk:4D4850 (page does not exist)">talk</a>) 20:04, 23 June 2022 (UTC)</dd></dl></dd></dl>
<dl><dd>I'm fairly sure that the model itself is almost certainly not sentient, even by the much lower bar presented by the strict dictionary definition.  Rather, it seems much more likely to me that in order to continue texts involving characters, the model must in turn learn to create a model of some level of humanlike mind, even if a very loose and abstract one.<a href="/wiki/index.php?title=User:Somdudewillson&amp;action=edit&amp;redlink=1" class="new" title="User:Somdudewillson (page does not exist)">Somdudewillson</a> (<a href="/wiki/index.php?title=User_talk:Somdudewillson&amp;action=edit&amp;redlink=1" class="new" title="User talk:Somdudewillson (page does not exist)">talk</a>) 22:52, 22 June 2022 (UTC)
<dl><dd>Have you actually looked at <a rel="nofollow" class="external text" href="https://www.merriam-webster.com/dictionary/sentient">the dictionary definitions</a>? How is a simple push-button switch connected to a battery and a lamp not "responsive to sense impressions"? How is a simple motion sensor not "aware" of whether something is moving in front of it? How is the latest cellphone's camera not as finely sensitive to visual perception as a typical human eye? Wikipedia's definition, "the capacity to experience feelings and sensations" is similarly met by simple devices. The word doesn't mean what everyone arguing about it thinks it means. <a href="/wiki/index.php/Special:Contributions/172.69.134.131" title="Special:Contributions/172.69.134.131">172.69.134.131</a> 23:04, 22 June 2022 (UTC)
<dl><dd>Or, it doesn't mean much at all, to start with. <a href="/wiki/index.php/Special:Contributions/172.70.90.173" title="Special:Contributions/172.70.90.173">172.70.90.173</a> 11:29, 23 June 2022 (UTC)</dd></dl></dd></dl></dd></dl>
<p>What is “What you don't understand is that Turing intended his test as an illustration of the...” likely to end with? <a href="/wiki/index.php/Special:Contributions/172.70.230.75" title="Special:Contributions/172.70.230.75">172.70.230.75</a> 13:23, 21 June 2022 (UTC)
</p>
<dl><dd>The ease with which someone at the other end of a teletype can trick you into believing they are male instead of female, or vice-versa. See <a href="https://en.wikipedia.org/wiki/Turing_test" class="extiw" title="wikipedia:Turing test">Turing test</a>. See also below. <a href="/wiki/index.php/Special:Contributions/172.69.134.131" title="Special:Contributions/172.69.134.131">172.69.134.131</a> 22:18, 22 June 2022 (UTC)</dd></dl>
<p>In response to the above: I believe the original "Turing Test" wasn't supposed to be a proof that an AI could think or was conscious (something people associate with it now), but rather just to show that a sufficiently advanced AI could imitate humans in certain intelligent behaviors (such as conversation), which was a novel thought for the time.  Now that AI are routinely having conversations and creating art which seems to rival casual attempts by humans, this limited scope of the test doesn't seem all that impressive. "Turing Test" therefore is a modern shorthand for determining whether computers can think, even though Turing himself didn't think that such a question was well-formed. <a href="/wiki/index.php/User:Dextrous_Fred" title="User:Dextrous Fred">Dextrous Fred</a> (<a href="/wiki/index.php?title=User_talk:Dextrous_Fred&amp;action=edit&amp;redlink=1" class="new" title="User talk:Dextrous Fred (page does not exist)">talk</a>) 13:37, 21 June 2022 (UTC)
</p><p>I thought the trolley problem was in its original form not about the relative value of lives, but people's perception of the relative moral implications or the psychological impact of the concept of letting someone die by not doing anything, versus taking affirmative action that causes a death, where people would say they would be unwilling to do something that would cause an originally safe person to die in order to save multiple other people who would die if they did nothing, but then people kept coming up with variations of it that changed the responses or added complications (like they found more people would be willing to pull a lever to change the track killing one person versus something like pushing a very fat man off an overpass above the track to stop the trolley, or specifying something about what kind of people are on the track.  Btw, I saw a while ago a party card game called "murder by trolley" based on the concept, with playing cards for which people are on tracks and a judge deciding which track to send the trolley on each round.--<a href="/wiki/index.php/Special:Contributions/172.70.130.5" title="Special:Contributions/172.70.130.5">172.70.130.5</a> 22:12, 21 June 2022 (UTC)
</p><p>Added refs to comics on the problems in the explanation. But there where actually (too?) many. Maybe we should create categories especially for Turing related comics, and maybe also for Trolley problem? The Category: Trolley Problem gives it self. But what about Turing? There are also comics that refer to the halting problem. Also by Turing. Should it rather be the person, like comics featuring real persons, saying that every time his problems is referred to it refers to him? Or should it be Turing as a category for both Turing text, Turing Complete and Halting problem? Help. I would have created it, if I had a good idea for a name. Not sure there are enough Trolley comics yet? --<a href="/wiki/index.php/User:Kynde" title="User:Kynde">Kynde</a> (<a href="/wiki/index.php/User_talk:Kynde" title="User talk:Kynde">talk</a>) 09:11, 22 June 2022 (UTC)
</p>
<dl><dd>Interesting that I found a long-standing typo in a past Explanation that got requoted, thanks to its inclusion. I could have [sic]ed it, I suppose, but I corrected both versions instead. And as long as LaMDA never explicitly repeated the error I don't think it matters much that I've changed the very thing we might imagine it could have been drawing upon for its Artifical Imagination.&#160;;) <a href="/wiki/index.php/Special:Contributions/141.101.99.32" title="Special:Contributions/141.101.99.32">141.101.99.32</a> 11:40, 22 June 2022 (UTC)</dd>
<dd>My view is that Turing should be a good category. Trolley Problem, I'm not sure if there's been enough comics to warrant it? If more than 4 or 5, I'd say go for it. <a href="/wiki/index.php/User:NiceGuy1" title="User:NiceGuy1">NiceGuy1</a> (<a href="/wiki/index.php/User_talk:NiceGuy1" title="User talk:NiceGuy1">talk</a>) 05:35, 25 June 2022 (UTC)</dd></dl>
<p>Randall was born in 1984, and Jurrasic Park was released in 1993. That makes him around nine years old at the time of release. So it really could have been a childhood favorite of his. And it suddenly makes me feel old. <a href="/wiki/index.php/User:These_Are_Not_The_Comments_You_Are_Looking_For" title="User:These Are Not The Comments You Are Looking For">These Are Not The Comments You Are Looking For</a> (<a href="/wiki/index.php/User_talk:These_Are_Not_The_Comments_You_Are_Looking_For" title="User talk:These Are Not The Comments You Are Looking For">talk</a>) 06:11, 28 June 2022 (UTC)
</p>
<h2><span class="mw-headline" id="OpenAI_Davinci_completions_of_the_three_statements">OpenAI Davinci completions of the three statements</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/wiki/index.php?title=Talk:2635:_Superintelligent_AIs&amp;action=edit&amp;section=T-1" title="Talk:2635: Superintelligent AIs">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>From <a rel="nofollow" class="external free" href="https://beta.openai.com/playground">https://beta.openai.com/playground</a> with default settings:
</p>
<dl><dd>Please complete this statement: But suppose the AI in the the box told the human that...</dd></dl>
<dl><dd><dl><dt>there was no AI in the box</dt></dl></dd></dl>
<dl><dd>Please complete this statement: What you don't understand is that Turing intended his test as an illustration of the...</dd></dl>
<dl><dd><dl><dt>limitations of machines</dt></dl></dd></dl>
<dl><dd>Please complete this statement: In my scenario, the runaway trolley has three tracks...</dd></dl>
<dl><dd><dl><dt>and the AI is on one of them</dt></dl></dd></dl>
<p>I like all of those very much, but I'm not sure they should be included in the explaination. <a href="/wiki/index.php/Special:Contributions/162.158.166.235" title="Special:Contributions/162.158.166.235">162.158.166.235</a> 23:27, 22 June 2022 (UTC)
</p>
<dl><dd>Those are all thoughtful, and the 1st and 3rd are pretty funny. It might be worth mentioning them in the Explanation. <a href="/wiki/index.php/Special:Contributions/172.68.132.96" title="Special:Contributions/172.68.132.96">172.68.132.96</a> 22:10, 3 July 2022 (UTC)
<dl><dd>These need to be in the explanation. <a href="/wiki/index.php/Special:Contributions/172.71.150.29" title="Special:Contributions/172.71.150.29">172.71.150.29</a> 07:17, 24 August 2022 (UTC)</dd></dl></dd></dl>
<h2><span class="mw-headline" id="Discussion_of_AI_philosophy.2C_ethics.2C_and_related_issues">Discussion of AI philosophy, ethics, and related issues</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/wiki/index.php?title=Talk:2635:_Superintelligent_AIs&amp;action=edit&amp;section=T-2" title="Talk:2635: Superintelligent AIs">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Since there are a lot of disjointed conversations regarding ethics, morals, philosophy, and what even is sentience on this talk page, please discuss here, so discussion about the comic itself isn't flooded by philosophy. <a href="/wiki/index.php?title=User:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User:4D4850 (page does not exist)">4D4850</a> (<a href="/wiki/index.php?title=User_talk:4D4850&amp;action=edit&amp;redlink=1" class="new" title="User talk:4D4850 (page does not exist)">talk</a>) 20:07, 23 June 2022 (UTC)
</p>
<dl><dd>Has anyone created an AI chatbot which represents a base-level chatbot after the human equivalent of smoking pot? <a href="/wiki/index.php/Special:Contributions/172.70.206.213" title="Special:Contributions/172.70.206.213">172.70.206.213</a> 22:30, 24 June 2022 (UTC)
<dl><dd>Well, famously (or not, but I'll let you search for the details if you weren't aware of it), there was the conversation engineered directly between ELIZA (the classic 'therapist'/doctor chatbot) and PARRY (emulates a paranoid schizophrenic personality), 8n a zero-human conversation. The latter is arguably being close to what you're asking about. And there's been the best part of half a century of academic, commercial and hobbyist development since then, so no doubt there'd be many more serious and/or for-the-lols 'reskins' or indeed entirely regrown personalities, that may involve drugs (simulated or otherwise) as key influences... <a href="/wiki/index.php/Special:Contributions/172.70.85.177" title="Special:Contributions/172.70.85.177">172.70.85.177</a> 01:30, 25 June 2022 (UTC)</dd>
<dd>A video by DougDoug on Youtube (although making decisions about what video game characters would win in a fight rather than being used as a chatbot) shows that Inferkit may fit the bill (I don't know exactly how pot affects capability to converse, but I would imagine it would affect the actual conversation (rather than ability to produce coherent words with one's mouth) somewhat similarly to alchohol)</dd></dl></dd></dl>
 </div>

<!-- 
NewPP limit report
Cached time: 20231019064117
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.054 seconds
Real time usage: 0.071 seconds
Preprocessor visited node count: 506/1000000
Preprocessor generated node count: 1648/1000000
Post‐expand include size: 94194/2097152 bytes
Template argument size: 1534/2097152 bytes
Highest expansion depth: 10/40
Expensive parser function count: 2/100
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   29.583      1 -total
 29.48%    8.721      1 Template:comic
 25.65%    7.589     25 Template:w
 24.17%    7.149      1 Template:comic_discussion
  8.83%    2.613      1 Template:citation_needed
  7.76%    2.296      1 Talk:2635:_Superintelligent_AIs
  5.07%    1.500      1 Template:cn
  4.34%    1.285      2 Template:LATESTCOMIC
  3.77%    1.114      1 MediaWiki:Mainpage
-->
</div>
<!-- Saved in parser cache with key expla0_db423085716:pcache:idhash:25379-0!canonical and timestamp 20231019064117 and revision id 306467
 -->
</div>					<div class="printfooter">
						Retrieved from "<a dir="ltr" href="https://www.explainxkcd.com/wiki/index.php?title=2635:_Superintelligent_AIs&amp;oldid=306467">https://www.explainxkcd.com/wiki/index.php?title=2635:_Superintelligent_AIs&amp;oldid=306467</a>"					</div>
				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/index.php/Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="/wiki/index.php/Category:All_comics" title="Category:All comics">All comics</a></li><li><a href="/wiki/index.php/Category:Comics_from_2022" title="Category:Comics from 2022">Comics from 2022</a></li><li><a href="/wiki/index.php/Category:Comics_from_June" title="Category:Comics from June">Comics from June</a></li><li><a href="/wiki/index.php/Category:Monday_comics" title="Category:Monday comics">Monday comics</a></li><li><a href="/wiki/index.php/Category:Pages_using_the_%22citation_needed%22_template" title="Category:Pages using the &quot;citation needed&quot; template">Pages using the &quot;citation needed&quot; template</a></li><li><a href="/wiki/index.php/Category:Comics_featuring_Cueball" title="Category:Comics featuring Cueball">Comics featuring Cueball</a></li><li><a href="/wiki/index.php/Category:Comics_featuring_Megan" title="Category:Comics featuring Megan">Comics featuring Megan</a></li><li><a href="/wiki/index.php/Category:Artificial_Intelligence" title="Category:Artificial Intelligence">Artificial Intelligence</a></li><li><a href="/wiki/index.php/Category:Philosophy" title="Category:Philosophy">Philosophy</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>

			<div id="mw-head">
									<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/index.php/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/index.php/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/wiki/index.php?title=Special:CreateAccount&amp;returnto=2635%3A+Superintelligent+AIs" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/wiki/index.php?title=Special:UserLogin&amp;returnto=2635%3A+Superintelligent+AIs" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
														<li id="ca-nstab-main" class="selected"><span><a href="/wiki/index.php/2635:_Superintelligent_AIs" title="View the content page [c]" accesskey="c">Page</a></span></li>
							<li id="ca-talk"><span><a href="/wiki/index.php/Talk:2635:_Superintelligent_AIs" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Discussion</a></span></li>
						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>

						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
														<li id="ca-view" class="selected"><span><a href="/wiki/index.php/2635:_Superintelligent_AIs">Read</a></span></li>
							<li id="ca-edit"><span><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li>
							<li id="ca-history" class="collapsible"><span><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>
						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<h3 id="p-cactions-label"><span>More</span></h3>

						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>

						<form action="/wiki/index.php" id="searchform">
							<div id="simpleSearch">
							<input type="search" name="search" placeholder="Search explain xkcd" title="Search explain xkcd [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search the pages for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/index.php/Main_Page"  title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id='p-navigation' aria-labelledby='p-navigation-label'>
			<h3 id='p-navigation-label'>Navigation</h3>

			<div class="body">
									<ul>
						<li id="n-mainpage-description"><a href="/wiki/index.php/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-Latest-comic"><a href="/wiki/index.php/2843">Latest comic</a></li><li id="n-portal"><a href="/wiki/index.php/explain_xkcd:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-xkcd-com"><a href="//xkcd.com" rel="nofollow">xkcd.com</a></li><li id="n-recentchanges"><a href="/wiki/index.php/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-randompage"><a href="/wiki/index.php/Special:Random" title="Load a random page [x]" accesskey="x">Random page</a></li><li id="n-All-comics"><a href="/wiki/index.php/List_of_all_comics">All comics</a></li><li id="n-Browse-comics"><a href="/wiki/index.php/Category:Comics">Browse comics</a></li><li id="n-RSS-feed"><a href="//explainxkcd.com/rss.xml" rel="nofollow">RSS feed</a></li><li id="n-help"><a href="https://www.mediawiki.org/wiki/Help:Contents" title="The place to find out">Help</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id='p-tb' aria-labelledby='p-tb-label'>
			<h3 id='p-tb-label'>Tools</h3>

			<div class="body">
									<ul>
						<li id="t-whatlinkshere"><a href="/wiki/index.php/Special:WhatLinksHere/2635:_Superintelligent_AIs" title="A list of all wiki pages that link here [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/index.php/Special:RecentChangesLinked/2635:_Superintelligent_AIs" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-specialpages"><a href="/wiki/index.php/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-print"><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li><li id="t-permalink"><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;oldid=306467" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/wiki/index.php?title=2635:_Superintelligent_AIs&amp;action=info" title="More information about this page">Page information</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id='p-' aria-labelledby='p--label'>
			<h3 id='p--label'></h3>

			<div class="body">
				<div class='g-follow' data-annotation='none' data-height='20' data-href='https://plus.google.com/100547197257043990051' data-rel='publisher'></div>

<script type='text/javascript'>
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/platform.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>
<a href='https://twitter.com/explainxkcd' class='twitter-follow-button' data-show-count='false' data-show-screen-name='false'>Follow @explainxkcd</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
<div id='fb-root'></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = '//connect.facebook.net/en_US/all.js#xfbml=1';
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<div class='fb-like' data-href='https://www.facebook.com/explainxkcd' data-layout='button' data-action='like' data-show-faces='false'></div>
<style>#pw{position:relative;height:620px;}#lp{position:relative;height:610px;}</style><div id='pw'><p></p><div id='lp'><a href='http://www.lunarpages.com/explainxkcd/'><img src='//www.explainxkcd.com/wiki/lunarpages_160x600.jpg'></img></a></div></div>
			</div>
		</div>
			<div class="portal" role="navigation" id='p-Ads' aria-labelledby='p-Ads-label'>
			<h3 id='p-Ads-label'>Ads</h3>

			<div class="body">
				<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block;" 
     data-ad-client="ca-pub-7040100948805002"
     data-ad-format="auto"
     enable_page_level_ads="true"
     data-ad-type="text">
</ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script><script>$('#p-Ads').addClass('persistent');</script>			</div>
		</div>
				</div>
		</div>
		<div id="footer" role="contentinfo">
							<ul id="footer-info">
											<li id="footer-info-lastmod"> This page was last edited on 18 February 2023, at 10:04.</li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="/wiki/index.php/explain_xkcd:Privacy_policy" title="explain xkcd:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="/wiki/index.php/explain_xkcd:About" class="mw-redirect" title="explain xkcd:About">About explain xkcd</a></li>
											<li id="footer-places-disclaimer"><a href="/wiki/index.php/explain_xkcd:General_disclaimer" title="explain xkcd:General disclaimer">Disclaimers</a></li>
									</ul>
										<ul id="footer-icons" class="noprint">
											<li id="footer-poweredbyico">
							<a href="//www.mediawiki.org/"><img src="/wiki/resources/assets/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/wiki/resources/assets/poweredby_mediawiki_132x47.png 1.5x, /wiki/resources/assets/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a><a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img src="https://i.creativecommons.org/l/by-sa/3.0/88x31.png" alt="Creative Commons License" width="88" height="31"/></a>						</li>
									</ul>
						<div style="clear:both"></div>
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.054","walltime":"0.071","ppvisitednodes":{"value":506,"limit":1000000},"ppgeneratednodes":{"value":1648,"limit":1000000},"postexpandincludesize":{"value":94194,"limit":2097152},"templateargumentsize":{"value":1534,"limit":2097152},"expansiondepth":{"value":10,"limit":40},"expensivefunctioncount":{"value":2,"limit":100},"timingprofile":["100.00%   29.583      1 -total"," 29.48%    8.721      1 Template:comic"," 25.65%    7.589     25 Template:w"," 24.17%    7.149      1 Template:comic_discussion","  8.83%    2.613      1 Template:citation_needed","  7.76%    2.296      1 Talk:2635:_Superintelligent_AIs","  5.07%    1.500      1 Template:cn","  4.34%    1.285      2 Template:LATESTCOMIC","  3.77%    1.114      1 MediaWiki:Mainpage"]},"cachereport":{"timestamp":"20231019064117","ttl":86400,"transientcontent":false}}});});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":65});});</script>
	</body>
</html>
